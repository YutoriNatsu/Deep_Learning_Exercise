{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BLEUscore as _bleu\n",
    "import Dataloader as _dl\n",
    "\n",
    "import config\n",
    "import Model\n",
    "import utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cfg = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = _dl.E2EDataset(mode='train', max_src_len=cfg.max_src_len, max_tgt_len=cfg.max_tgt_len)\n",
    "\n",
    "dev_set = _dl.E2EDataset(mode='dev', max_src_len=cfg.max_src_len, max_tgt_len=cfg.max_tgt_len, field_tokenizer=train_set.field_tokenizer, tokenizer=train_set.tokenizer) \n",
    "\n",
    "test_set = _dl.E2EDataset(mode='test', max_src_len=cfg.max_src_len, max_tgt_len=cfg.max_tgt_len, field_tokenizer=train_set.field_tokenizer, tokenizer=train_set.tokenizer) \n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=cfg.batch_size, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.E2EModel(cfg, src_vocab_size=train_set.tokenizer.vocab_size, tgt_vocab_size=train_set.tokenizer.vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_ID = 0\n",
    "\n",
    "# 初始化batch大小，epoch数，损失函数，优化器等 \n",
    "batch_size = cfg.batch_size \n",
    "weight = torch.ones(train_set.tokenizer.vocab_size) \n",
    "weight[PAD_ID] = 0\n",
    "\n",
    "# 定义分数评估 \n",
    "scorer = _bleu.BLEUScore(max_ngram=4) \n",
    "\n",
    "# 定义损失函数 \n",
    "criterion = nn.NLLLoss(weight, size_average=True).to(device) \n",
    "\n",
    "# 定义优化器 \n",
    "optimizer = optim.SGD(params=model.parameters(), lr=cfg.learning_rate) \n",
    "\n",
    "# 定义学习率下降 \n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200) \n",
    "MAX_EPOCH = cfg.n_epochs \n",
    "VAL_NUM = cfg.val_num \n",
    "\n",
    "best_bleu = 0.0  # 最高bleu \n",
    "loss_li = [] \n",
    "bleu_li = [] \n",
    "lr_li = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    "from numpy import newaxis\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model, iterator, iter): \n",
    "    print_loss = 0.0  # 输出loss \n",
    "    model.train() \n",
    "    with tqdm(total=len(iterator), desc='epoch{} [train]'.format(iter), file=stdout) as t: \n",
    "        for i, batch in enumerate(iterator):\n",
    "            src, tgt = batch # 移至设备上 \n",
    "            src = src.to(device).transpose(0, 1) \n",
    "            tgt = tgt.to(device).transpose(0, 1)\n",
    "\n",
    "            optimizer.zero_grad()  # 初始化梯度值 \n",
    "            \n",
    "            # Forward \n",
    "            logits = model((src, tgt)) \n",
    "            vocab_size = logits.size()[-1] \n",
    "            logits = logits.contiguous().view(-1, vocab_size) \n",
    "            targets = tgt.contiguous().view(-1, 1).squeeze(1) \n",
    "            loss = criterion(logits, targets.long()) \n",
    "            print_loss += loss.data.item() \n",
    "\n",
    "            # Backward \n",
    "            loss.backward()  # 反向传播求梯度 \n",
    "            \n",
    "            # Update \n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "            # Backward \n",
    "            loss.backward()  # 反向传播求梯度 \n",
    "            \n",
    "            # Update \n",
    "            optimizer.step()  # 更新参数 \n",
    "            t.set_postfix(loss=print_loss / (i + 1), lr=scheduler.get_last_lr()[0]) \n",
    "            t.update(1) \n",
    "\n",
    "            loss_li.append(print_loss / len(iterator)) \n",
    "            lr_li.append(scheduler.get_last_lr()[0]) \n",
    "            scheduler.step() \n",
    "\n",
    "def evaluate(model, iterator, iter): \n",
    "    global best_bleu \n",
    "    model.eval() \n",
    "    bleu = 0.0 \n",
    "    total_num = 0 \n",
    "    # 重置分数统计器 \n",
    "    scorer.reset() \n",
    "    with torch.no_grad(): \n",
    "        for data in tqdm(iterator, desc='{} [valid]'.format(\" \" * (5 + len(str(iter)))), file=stdout): \n",
    "            # 重置分数统计器 \n",
    "            src, tgt, lex, muti_tgt = data \n",
    "            src = torch.as_tensor(src[:, newaxis]).to(device) \n",
    "            sentence, attention = model.predict(src) \n",
    "            # 解码句子 \n",
    "            sentence = train_set.tokenizer.decode(sentence).replace('[NAME]', lex[0]).replace('[NEAR]', lex[1]) \n",
    "            scorer.append(sentence, muti_tgt) \n",
    "        \n",
    "        bleu = scorer.score()  # 计算BLEU \n",
    "        bleu_li.append(bleu) \n",
    "        print(\"BLEU SCORE: {:.4f}\".format(bleu)) \n",
    "        if bleu > best_bleu: \n",
    "            best_bleu = bleu \n",
    "            torch.save(model, cfg.model_save_path)  # 保存模型 参数 网络 路径 \n",
    "            print(\"保存模型成功！\") \n",
    "\n",
    "def draw_carve(title, save_path, x, y): \n",
    "    plt.clf()  # 清空图像 \n",
    "    plt.title(title)  # 图像标题 \n",
    "    plt.plot(range(x), y)  # 绘制图像 \n",
    "    plt.savefig(save_path)  # 保存图像 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集用于训练，验证集用于评估 \n",
    "for epoch in range(MAX_EPOCH): \n",
    "    train(model, train_loader, epoch)\n",
    "    # 指定轮数验证 \n",
    "    if epoch % VAL_NUM == 0: \n",
    "        evaluate(model, dev_set, epoch) \n",
    "\n",
    "# 绘制验证BLEU曲线 \n",
    "draw_carve(\"valid_bleu\", './valid_bleu.png', epoch // VAL_NUM + 1, bleu_li) \n",
    "# 绘制训练LOSS曲线 \n",
    "draw_carve(\"train_loss\", './train_loss.png', epoch + 1, loss_li) \n",
    "# 绘制训练LR曲线 \n",
    "draw_carve(\"train_lr\", './train_lr.png', epoch + 1, lr_li) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() \n",
    "with torch.no_grad(): \n",
    "    for data in tqdm(test_set, desc='[test]', file=stdout): \n",
    "        src, tgt, lex, _ = data \n",
    "        src = torch.as_tensor(src[:, newaxis]).to(device) \n",
    "        # 模型预测 \n",
    "        sentence, attention = model.predict(src) \n",
    "        # 解码句子 \n",
    "        sentence = train_set.tokenizer.decode(sentence).replace('[NAME]', lex[0]).replace('[NEAR]', lex[1]) \n",
    "        # 写入文本 \n",
    "        with open(cfg.result_save_path, 'a+', encoding='utf-8') as f: \n",
    "            f.write(sentence + '.\\n') \n",
    "print('Finished Testing!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
